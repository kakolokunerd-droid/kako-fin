# ü§ñ Configura√ß√£o de Provedores de IA para Insights

## Vis√£o Geral

O Kako Fin agora suporta m√∫ltiplos provedores de IA para gerar insights financeiros. Voc√™ pode escolher entre op√ß√µes **gratuitas** ou com **custo fixo**, sem necessidade de configura√ß√£o de faturamento.

## üÜì Provedores Gratuitos Recomendados

### 1. **Groq** ‚≠ê (Recomendado)

**Por que escolher:**

- ‚úÖ **Gratuito e generoso**: 14,400 requests/dia
- ‚úÖ **Muito r√°pido**: Respostas em milissegundos
- ‚úÖ **Sem necessidade de cart√£o de cr√©dito**
- ‚úÖ **F√°cil de configurar**

**Como configurar:**

1. **Obter API Key:**

   - Acesse: https://console.groq.com/
   - Crie uma conta (gratuita)
   - V√° em "API Keys"
   - Clique em "Create API Key"
   - Copie a chave

2. **Configurar no projeto:**

   - Crie/edite o arquivo `.env.local` na raiz do projeto
   - Adicione:
     ```env
     VITE_AI_PROVIDER=groq
     VITE_AI_API_KEY=sua_chave_groq_aqui
     VITE_AI_MODEL=llama-3.3-70b-versatile
     ```

3. **Reiniciar o servidor:**
   ```bash
   npm run dev
   ```

**Modelos dispon√≠veis:**

- `llama-3.3-70b-versatile` (recomendado - atualizado)
- `llama-3.1-8b-instant`
- `mixtral-8x7b-32768`
- `llama-3.1-70b-versatile` (descontinuado - n√£o usar)

---

### 2. **Hugging Face** (Gratuito com rate limits)

**Por que escolher:**

- ‚úÖ **Gratuito** (com rate limits)
- ‚úÖ **Muitos modelos dispon√≠veis**
- ‚úÖ **Sem necessidade de cart√£o**

**Como configurar:**

1. **Obter API Key:**

   - Acesse: https://huggingface.co/
   - Crie uma conta (gratuita)
   - V√° em Settings ‚Üí Access Tokens
   - Crie um novo token
   - Copie o token

2. **Configurar no projeto:**
   ```env
   VITE_AI_PROVIDER=huggingface
   VITE_AI_API_KEY=seu_token_huggingface_aqui
   VITE_AI_MODEL=mistralai/Mistral-7B-Instruct-v0.2
   ```

**Modelos dispon√≠veis:**

- `mistralai/Mistral-7B-Instruct-v0.2`
- `meta-llama/Llama-2-7b-chat-hf`
- `google/flan-t5-large`

**‚ö†Ô∏è Nota:** Hugging Face pode ter rate limits mais restritivos.

---

### 3. **Ollama** (100% Gratuito - Local)

**Por que escolher:**

- ‚úÖ **100% gratuito** (roda localmente)
- ‚úÖ **Sem limites de uso**
- ‚úÖ **Privacidade total** (dados n√£o saem do seu computador)
- ‚úÖ **Sem necessidade de internet** (ap√≥s instalar)

**Como configurar:**

1. **Instalar Ollama:**

   - Acesse: https://ollama.ai/
   - Baixe e instale o Ollama
   - Abra o terminal e execute:
     ```bash
     ollama pull llama3.1
     ```

2. **Configurar no projeto:**

   ```env
   VITE_AI_PROVIDER=ollama
   VITE_AI_MODEL=llama3.1
   VITE_AI_BASE_URL=http://localhost:11434
   ```

   (N√£o precisa de API key para Ollama)

3. **Iniciar Ollama:**
   - O Ollama deve estar rodando localmente
   - Por padr√£o, roda em `http://localhost:11434`

**Modelos dispon√≠veis:**

- `llama3.1` (recomendado)
- `mistral`
- `codellama`
- `phi3`

**‚ö†Ô∏è Nota:** Requer que o Ollama esteja instalado e rodando no computador do usu√°rio.

---

## üí∞ Provedores com Custo (Opcional)

### 4. **OpenAI** (Pode ter tier gratuito limitado)

**Como configurar:**

```env
VITE_AI_PROVIDER=openai
VITE_AI_API_KEY=sua_chave_openai_aqui
VITE_AI_MODEL=gpt-3.5-turbo
```

**‚ö†Ô∏è Nota:** OpenAI pode requerer faturamento para uso real.

---

### 5. **Google Gemini** (Original - Requer faturamento)

**Como configurar:**

```env
VITE_AI_PROVIDER=gemini
VITE_AI_API_KEY=sua_chave_gemini_aqui
VITE_AI_MODEL=gemini-3-flash-preview
```

**‚ö†Ô∏è Nota:** Requer configura√ß√£o de faturamento no Google Cloud.

---

## üìã Compara√ß√£o R√°pida

| Provedor         | Custo    | Velocidade          | Limites          | Faturamento      |
| ---------------- | -------- | ------------------- | ---------------- | ---------------- |
| **Groq** ‚≠ê      | Gratuito | ‚ö°‚ö°‚ö° Muito r√°pido | 14,400/dia       | ‚ùå N√£o           |
| **Hugging Face** | Gratuito | ‚ö°‚ö° R√°pido         | Rate limits      | ‚ùå N√£o           |
| **Ollama**       | Gratuito | ‚ö°‚ö°‚ö° Muito r√°pido | Sem limites      | ‚ùå N√£o           |
| **OpenAI**       | Vari√°vel | ‚ö°‚ö° R√°pido         | Depende do plano | ‚ö†Ô∏è Pode precisar |
| **Gemini**       | Vari√°vel | ‚ö°‚ö° R√°pido         | Depende do plano | ‚úÖ Sim           |

---

## üöÄ Configura√ß√£o R√°pida (Recomendado: Groq)

1. **Crie o arquivo `.env.local` na raiz do projeto:**

   ```env
   VITE_AI_PROVIDER=groq
   VITE_AI_API_KEY=sua_chave_groq_aqui
   ```

2. **Obtenha sua chave em:** https://console.groq.com/

3. **Reinicie o servidor:**

   ```bash
   npm run dev
   ```

4. **Pronto!** Os Insights agora usar√£o Groq.

---

## üîß Vari√°veis de Ambiente

### Vari√°veis Dispon√≠veis:

- `VITE_AI_PROVIDER`: Provedor a usar (`groq`, `huggingface`, `ollama`, `openai`, `gemini`)
- `VITE_AI_API_KEY`: Chave da API (n√£o necess√°rio para Ollama)
- `VITE_AI_MODEL`: Modelo espec√≠fico a usar (opcional, usa padr√£o se n√£o especificado)
- `VITE_AI_BASE_URL`: URL base para Ollama ou APIs customizadas (opcional)

### Exemplo Completo:

```env
# Provedor de IA
VITE_AI_PROVIDER=groq

# Chave da API
VITE_AI_API_KEY=gsk_sua_chave_aqui

# Modelo espec√≠fico (opcional)
VITE_AI_MODEL=llama-3.3-70b-versatile

# Para Ollama (opcional)
VITE_AI_BASE_URL=http://localhost:11434
```

---

## üêõ Troubleshooting

### Erro: "API_KEY n√£o configurada"

**Solu√ß√£o:**

1. Verifique se o arquivo `.env.local` existe
2. Confirme que a vari√°vel `VITE_AI_API_KEY` est√° configurada
3. Reinicie o servidor ap√≥s adicionar a vari√°vel

### Erro: "Limite de uso atingido"

**Solu√ß√£o:**

- Para Groq: Aguarde ou verifique seu uso em https://console.groq.com/
- Para Hugging Face: Aguarde alguns minutos ou considere usar outro provedor
- Considere usar Ollama (sem limites)

### Erro: "Ollama n√£o encontrado"

**Solu√ß√£o:**

1. Instale o Ollama: https://ollama.ai/
2. Execute `ollama pull llama3.1`
3. Certifique-se de que o Ollama est√° rodando

### Quer trocar de provedor?

Simplesmente altere `VITE_AI_PROVIDER` no `.env.local` e reinicie o servidor!

---

## üìö Recursos

- **Groq Console:** https://console.groq.com/
- **Hugging Face:** https://huggingface.co/
- **Ollama:** https://ollama.ai/
- **OpenAI:** https://platform.openai.com/
- **Google AI Studio:** https://aistudio.google.com/

---

## ‚úÖ Recomenda√ß√£o Final

Para a maioria dos casos, **recomendamos usar Groq**:

- ‚úÖ Gratuito e generoso
- ‚úÖ Muito r√°pido
- ‚úÖ F√°cil de configurar
- ‚úÖ Sem necessidade de faturamento
- ‚úÖ Boa qualidade de respostas

Basta criar uma conta gratuita e configurar a chave no `.env.local`!
